{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7880,"databundleVersionId":862031,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:53:52.963870Z","iopub.execute_input":"2025-04-25T16:53:52.964458Z","iopub.status.idle":"2025-04-25T16:53:52.968227Z","shell.execute_reply.started":"2025-04-25T16:53:52.964429Z","shell.execute_reply":"2025-04-25T16:53:52.967462Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# import","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport torch\nimport torchvision\nimport pandas as pd\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torch.nn as nn\nfrom torchvision import models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.utils.data as data\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:53:52.969397Z","iopub.execute_input":"2025-04-25T16:53:52.969901Z","iopub.status.idle":"2025-04-25T16:53:52.991224Z","shell.execute_reply.started":"2025-04-25T16:53:52.969880Z","shell.execute_reply":"2025-04-25T16:53:52.990465Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"\n\n\nclass CustomImageDataset(Dataset):\n    \n    def __init__(self, img_dir , transform = None, target_transform = None):\n        self.img = glob.glob(img_dir)\n        self.transform = transform\n        self.to_tensor = torchvision.transforms.ToTensor()\n        self.target_transform = target_transform\n        self.labels = ['Black-grass', 'Charlock' , 'Cleavers' , 'Common Chickweed' , 'Common wheat' , 'Fat Hen' , 'Loose Silky-bent' , 'Maize' , 'Scentless Mayweed' , 'Shepherds Purse', 'Small-flowered Cranesbill' , 'Sugar beet']\n\n    def __len__(self):\n        return len(self.img)\n\n\n    def __getitem__(self, idx):\n        img_path = self.img[idx]\n        image = cv2.imread(img_path)\n        image = self.to_tensor(image)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        label = img_path.split('/')[-2]\n        idx = self.labels.index(label)\n        \n        # target = F.one_hot(torch.tensor(idx) , num_classes = len(self.labels))\n        # target = torch.tensor(target , dtype=torch.float32)\n        return image, idx\n\nclass TestDataset(Dataset):\n    def __init__(self, img_dir , transform = None, target_transform = None):\n        self.img = glob.glob(img_dir)\n        # self.name = os.path.basename(img_dir)\n        self.transform = transform\n        self.target_transform = target_transform\n        self.to_tensor = torchvision.transforms.ToTensor()\n\n    def __getitem__(self, idx):\n        img_path = self.img[idx]\n        image_name = os.path.basename(img_path)\n        image = cv2.imread(img_path)\n        image = self.to_tensor(image)\n        \n        if self.transform:\n            image = self.transform(image)\n\n        \n            \n        return image_name , image\n\n    def __len__(self):\n        return len(self.img)\n\n# if __name__ == '__main__': # int main()\n#    \n#     path = \"/kaggle/input/plant-seedlings-classification/train/*/*.png\"\n#     transform = transforms.Compose([transforms.Resize((256, 256))])\n#     plant_data = CustomImageDataset(path , transform = transform)\n\n#     dataloader = DataLoader(\n#     plant_data, \n#     batch_size=32,\n#     shuffle=True,   # set to True in training stage and False in others\n#     num_workers=8,  # for multi-processing\n#     pin_memory=True,\n#     )\n    \n#     for img, label in dataloader:\n#         print(img, label)\n    \n#     # print(\"here\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:53:52.992211Z","iopub.execute_input":"2025-04-25T16:53:52.992438Z","iopub.status.idle":"2025-04-25T16:53:53.006259Z","shell.execute_reply.started":"2025-04-25T16:53:52.992420Z","shell.execute_reply":"2025-04-25T16:53:53.005630Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Resnet 50","metadata":{}},{"cell_type":"code","source":"class resnet_50(nn.Module):\n    def __init__(self, num_classes = 12):\n        super(resnet_50, self).__init__()\n        self.resnet50 = models.resnet50(pretrained = True) \n        self.resnet50.fc = nn.Sequential(\n                nn.Linear(2048, num_classes),\n                nn.ReLU(True),\n                # nn.Dropout(),\n                # nn.Linear(1024, 512),\n                # nn.ReLU(True),\n                # nn.Dropout(),\n                # nn.Linear(512, 128),\n                # nn.ReLU(True),\n                # nn.Dropout(),\n                # nn.Linear(128, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.resnet50(x)\n        return x\n\n\n# if __name__ == \"__main__\":\n#     model = resnet_50(12)\n#     print(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:53:53.006866Z","iopub.execute_input":"2025-04-25T16:53:53.007054Z","iopub.status.idle":"2025-04-25T16:53:53.023889Z","shell.execute_reply.started":"2025-04-25T16:53:53.007032Z","shell.execute_reply":"2025-04-25T16:53:53.023233Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"device_num = 0\ntrain_loss = []\ntrain_acc = []\nval_loss = []\nval_acc = []\ntrain_epoch = []\n\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    correct = 0\n    total_loss = 0\n    total_samples = len(train_loader.dataset)\n    \n    pbar = tqdm(enumerate(train_loader), total = len(train_loader), desc = f\"Epoch {epoch}\", unit = \"batch\")\n    for batch_idx, (data, target) in pbar:\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        \n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n\n        pred = output.argmax(dim = 1, keepdim=True) #predicted answer\n        correct += pred.eq(target.view_as(pred)).sum().item() #currect answer\n\n        total_loss += loss.item()\n        pbar.set_postfix({\"Loss\": total_loss / (batch_idx + 1), \"Acc\": correct / total_samples})\n\n    acc = round(correct / total_samples, 4)\n    train_acc.append(acc)\n    train_loss.append(total_loss / len(train_loader))\n\n    print('\\nTrain acc: ', acc, 'Train loss: ', total_loss / len(train_loader))\n   \n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)           \n            test_loss += F.cross_entropy(output, target, reduction = 'sum').item()       \n            pred = output.argmax(dim = 1, keepdim=True) #predicted answer\n            correct += pred.eq(target.view_as(pred)).sum().item() #currect answer\n\n    test_loss /= len(test_loader.dataset)\n    acc = round(correct / len(test_loader.dataset), 4)\n    val_loss.append(test_loss)\n    val_acc.append(acc)\n    print('\\r\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * acc), end='')\n\ndef draw(title, xlabel, ylabel, x, y1, y2, filename):\n    plt.figure()\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.plot(x, y1)\n    plt.plot(x, y2)\n    plt.legend(['train', 'valid'], loc='upper left')\n    plt.savefig(filename)\n\ndef main():\n    # train_dict, train_info_dict = load_data.read_image_folder((224, 224), \"./train\")\n    # whole_dataset = load_data.ImageDataset(train_dict[\"data\"], train_dict[\"labels\"])\n    path = \"/kaggle/input/plant-seedlings-classification/train/*/*.png\"\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.CenterCrop(224),\n        transforms.RandomHorizontalFlip(p = 0.5),\n        transforms.RandomVerticalFlip(p = 0.5),\n        transforms.RandomRotation(180),\n        transforms.RandomAffine(degrees = 45 , translate = (0.25 , 0.25) , scale = (0.5 , 1.5)),\n        # transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n    ])\n    plant_data = CustomImageDataset(path , transform = transform)\n    \n    # Random split\n    train_set_size = int(len(plant_data) * 0.8)\n    valid_set_size = len(plant_data) - train_set_size\n    train_set, valid_set = data.random_split(plant_data, [train_set_size, valid_set_size])\n\n    train_loader = DataLoader(train_set, batch_size = 64, shuffle = True)\n    valid_loader = DataLoader(valid_set, batch_size = 64)\n\n    with torch.cuda.device(device_num):\n        model = resnet_50(num_classes = 12).to(device_num)\n        adam = torch.optim.Adam(model.parameters(), lr = 1e-5 , weight_decay = 0.001)\n\n        for epoch in range(1, 31):\n            train_epoch.append(epoch)\n            train(model, device_num, train_loader, adam, epoch)\n            test(model, device_num, valid_loader)\n\n        #print loss graph\n        draw('train loss', 'epoch', 'loss', train_epoch, train_loss, val_loss,'resnet50_train_loss.jpg')\n        draw('train accuracy', 'epoch', 'accuracy', train_epoch, train_acc, val_acc,'resnet50_train_acc.jpg')\n        torch.save(model.state_dict(), 'resnet50.pt')\n\nif __name__ == \"__main__\":\n    main()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:53:53.082224Z","iopub.execute_input":"2025-04-25T16:53:53.082577Z","iopub.status.idle":"2025-04-25T17:03:45.535816Z","shell.execute_reply.started":"2025-04-25T16:53:53.082561Z","shell.execute_reply":"2025-04-25T17:03:45.534683Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 205MB/s]\nEpoch 1: 100%|██████████| 60/60 [02:14<00:00,  2.24s/batch, Loss=2.35, Acc=0.251] \n","output_type":"stream"},{"name":"stdout","text":"\nTrain acc:  0.2513 Train loss:  2.3504817048708597\n\nTest set: Average loss: 2.1183, Accuracy: 344/950 (36%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 60/60 [01:21<00:00,  1.36s/batch, Loss=1.87, Acc=0.452] \n","output_type":"stream"},{"name":"stdout","text":"\nTrain acc:  0.4518 Train loss:  1.872860187292099\n\nTest set: Average loss: 1.6527, Accuracy: 459/950 (48%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 60/60 [01:20<00:00,  1.34s/batch, Loss=1.54, Acc=0.516] \n","output_type":"stream"},{"name":"stdout","text":"\nTrain acc:  0.5161 Train loss:  1.5396237750848134\n\nTest set: Average loss: 1.4443, Accuracy: 505/950 (53%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 60/60 [01:20<00:00,  1.34s/batch, Loss=1.29, Acc=0.631] \n","output_type":"stream"},{"name":"stdout","text":"\nTrain acc:  0.6308 Train loss:  1.2854668875535329\n\nTest set: Average loss: 1.1082, Accuracy: 668/950 (70%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 60/60 [01:20<00:00,  1.35s/batch, Loss=0.953, Acc=0.745]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain acc:  0.745 Train loss:  0.9532226661841074\n\nTest set: Average loss: 0.7164, Accuracy: 789/950 (83%)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  38%|███▊      | 23/60 [00:31<00:51,  1.39s/batch, Loss=0.664, Acc=0.327]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/4168057172.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/4168057172.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/4168057172.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Epoch {epoch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2072396318.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":10},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"# from tqdm import tqdm\n# from torch.utils.data import DataLoader\n# import torchvision.transforms as transforms\n# import pandas as pd\n# import numpy as np\n# import torch\n# import torchvision\n\nimage_names_list = []\nans = []\ndevice_num = 0\nlabel = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat',\n        'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', \n        'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n\npath = '/kaggle/input/plant-seedlings-classification/test/*.png'\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n])\n\ntest_data = TestDataset(path , transform = transform)\nloader = DataLoader(test_data, batch_size = 1)\n\nwith torch.cuda.device(device_num):\n    model = resnet_50(num_classes = 12).cuda()\n    model.load_state_dict(torch.load('/kaggle/working/resnet50.pt'))\n    model.eval()\n    with torch.no_grad():\n        for image_names , data in tqdm(loader):\n            # image , idx = data\n            data = data.to(device_num)\n            output = model(data)\n            res = output.argmax(dim = 1, keepdim = True)\n            ans.append(label[res])\n            image_names_list.extend(list(image_names))\n\n\ndict = {'file' : image_names_list , 'species' : ans}\ndf = pd.DataFrame(dict)\ndf.to_csv('/kaggle/working/submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T17:03:45.536328Z","iopub.status.idle":"2025-04-25T17:03:45.536533Z","shell.execute_reply.started":"2025-04-25T17:03:45.536432Z","shell.execute_reply":"2025-04-25T17:03:45.536442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}